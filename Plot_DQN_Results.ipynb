{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"G:\\\\My Drive\\\\CS230Project\\\\trained_models\"\n",
    "figdir = \"G:\\\\My Drive\\\\CS230Project\\\\milestone2_figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying cause I haven't made a module yet\n",
    "class one_hot_hand_target:\n",
    "    '''agent class. Hand and cursor are one hot pixels in separate inputs channels'''\n",
    "    def __init__(self,npixelx,npixely,king_moves=False):\n",
    "        self.hand_set = False # bool whether hand is placed\n",
    "        self.target_set = False # bool whether target is placed\n",
    "        self.npixelx = npixelx # # size of screen in x\n",
    "        self.npixely = npixely # size of screen in y \n",
    "        self.observation_shape = [2,npixelx,npixely] # shape of inputs\n",
    "        self.target_radius = 1 # pixel radius considered as reaching the target \n",
    "        \n",
    "        \n",
    "        # encode hand state as one hot matrix - leave empty \n",
    "        self.hand = None \n",
    "        \n",
    "        # encode target state - leave empty until target is placed\n",
    "        self.target = None \n",
    "        \n",
    "        \n",
    "        if king_moves: # allow diagonal moves\n",
    "            self.num_actions = 8\n",
    "            self.actions = np.array([[1,0],\n",
    "                           [0,1],\n",
    "                           [-1,0],\n",
    "                           [0,-1],\n",
    "                           [1,1],\n",
    "                           [1,-1],\n",
    "                           [-1,1],\n",
    "                           [-1,-1]])\n",
    "        else:\n",
    "            self.num_actions = 4\n",
    "            self.actions = np.array([[1,0],\n",
    "                           [0,1],\n",
    "                           [-1,0],\n",
    "                           [0,-1]])\n",
    "            \n",
    "    def place_hand(self,x,y):\n",
    "        self.hand = np.array([x,y])\n",
    "        self.hand_set=True\n",
    "        \n",
    "        \n",
    "    def place_target(self,x,y):\n",
    "        self.target = np.array([x,y])\n",
    "        self.target_set = True\n",
    "        \n",
    "        \n",
    "    def init_trial(self,hx,hy,tx,ty):\n",
    "        # place hand\n",
    "        self.place_hand(hx,hy)\n",
    "        \n",
    "        # place target\n",
    "        self.place_target(tx,ty)\n",
    "        \n",
    "        \n",
    "        # calculate reward\n",
    "        reward = self.get_reward()\n",
    "        if reward>-1:\n",
    "          return self.get_state(),0,True\n",
    "        else:\n",
    "          return self.get_state(),-1,False\n",
    "        \n",
    "    def get_reward(self):\n",
    "        if np.linalg.norm(self.target-self.hand,2)<=self.target_radius:\n",
    "          return 0\n",
    "        else:\n",
    "          return -1\n",
    "        \n",
    "\n",
    "    def get_state(self):\n",
    "        screen = np.zeros((2,self.npixelx,self.npixely))\n",
    "        screen[0,self.hand[0],self.hand[1]]+=10\n",
    "        screen[1,self.target[0],self.target[1]]+=10\n",
    "        \n",
    "        return screen \n",
    "    \n",
    "    \n",
    "    def step(self,a):\n",
    "\n",
    "        action = self.actions[a,:]\n",
    "        self.hand[0]= np.minimum(np.maximum(self.hand[0]+action[0],0),self.npixelx-1)\n",
    "        self.hand[1]= np.minimum(np.maximum(self.hand[1]+action[1],0),self.npixely-1)\n",
    "        \n",
    "        \n",
    "        reward = self.get_reward()\n",
    "        if reward>-1:\n",
    "          return self.get_state(),0,True\n",
    "        else:\n",
    "          return self.get_state(),-1,False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'CnnDQN' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f83882bd8842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"DQN_16x16.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# initialize agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot_hand_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    591\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'CnnDQN' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# load model \n",
    "model = torch.load(os.path.join(basedir,\"DQN_16x16.pt\"))\n",
    "\n",
    "# initialize agent \n",
    "h = one_hot_hand_target(16,16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place hand and targets randomly\n",
    "\n",
    "\n",
    "# run model until target is reached\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ideal steps to target vs number of steps to reach target\n",
    "\n",
    "# ideal is just max(x distance, y distance) since diagonal steps can be taken for min(x distance, y distance) steps "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
